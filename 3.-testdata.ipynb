{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "df=pd.read_excel(\n",
    "     os.path.join(\"data\", \"reclamos_20201221_sin_clas.xlsx\"),\n",
    "     engine='openpyxl',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CASO_ID', 'DESCRIPCION_CIUDADANO', 'PETICION_CIUDADANO'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DESCRIPCION_CIUDADANO']=df['DESCRIPCION_CIUDADANO'].map(str).str.lower()\n",
    "df['PETICION_CIUDADANO']=df['PETICION_CIUDADANO'].map(str).str.lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data'] = df['DESCRIPCION_CIUDADANO'] + df['PETICION_CIUDADANO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, re\n",
    "\n",
    "def remove_punct(x):\n",
    "    comp = re.compile(\"[%s\\d]\" % re.escape(string.punctuation))\n",
    "    return \" \".join(comp.sub(\" \", str(x)).split()).lower()\n",
    "\n",
    "df['data']=df['data'].apply(remove_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import es_core_news_sm\n",
    "\n",
    "nlp = es_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sergio/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     conforme indicado oford xx sgd xx fecha noviem...\n",
      "1     haber activar seguro incendio adicional rotura...\n",
      "2     contratar seguro automotriz llamado seguro mag...\n",
      "3     mayo robar camioneta usar robar cajero aparece...\n",
      "4     ser propietario acción inmobiliaria estadio ár...\n",
      "                            ...                        \n",
      "95    padre don xx fallecer tenia cuatro acción gran...\n",
      "96    presentar según reglamento documentación hacer...\n",
      "97    octubre renovó seguro auto mismo aseguradora s...\n",
      "98    ingrese vehículo taller piamonte irarrazaval d...\n",
      "99    hacer reclamo siguiente aseguradora pagar corr...\n",
      "Name: data, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words=stopwords.words('spanish')\n",
    "def preprocess(text):\n",
    "  \t# Create Doc object\n",
    "    doc = nlp(text, disable=['ner', 'parser'])\n",
    "    # Generate lemmas\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    # Remove stopwords and non-alphabetic characters\n",
    "    a_lemmas = [lemma for lemma in lemmas \n",
    "            if lemma.isalpha() and lemma not in stop_words]\n",
    "    \n",
    "    return ' '.join(a_lemmas)\n",
    "  \n",
    "# Apply preprocess to ted['transcript']\n",
    "df['data'] = df['data'].apply(preprocess)\n",
    "print(df['data'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     conforme indicado oford xx sgd xx fecha noviem...\n",
      "1     haber activar seguro incendio adicional rotura...\n",
      "2     contratar seguro automotriz llamado seguro mag...\n",
      "3     mayo robar camioneta usar robar cajero aparece...\n",
      "4     ser propietario accion inmobiliaria estadio ar...\n",
      "                            ...                        \n",
      "95    padre don xx fallecer tenia cuatro accion gran...\n",
      "96    presentar segun reglamento documentacion hacer...\n",
      "97    octubre renovo seguro auto mismo aseguradora s...\n",
      "98    ingrese vehiculo taller piamonte irarrazaval d...\n",
      "99    hacer reclamo siguiente aseguradora pagar corr...\n",
      "Name: data, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "\n",
    "def strip_accents(string, accents=('COMBINING ACUTE ACCENT', 'COMBINING GRAVE ACCENT', 'COMBINING TILDE')):\n",
    "    accents = set(map(unicodedata.lookup, accents))\n",
    "    chars = [c for c in unicodedata.normalize('NFD', string) if c not in accents]\n",
    "    return unicodedata.normalize('NFC', ''.join(chars))\n",
    "\n",
    "df['data'] = df['data'].apply(strip_accents)\n",
    "print(df['data'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)\n",
    "    \n",
    "input_array = tokenizer.texts_to_sequences(df['data'].values)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_test = pad_sequences(input_array, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red Neuronal Recurrente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 100)          806800    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                3232      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 810,065\n",
      "Trainable params: 810,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten, SpatialDropout1D,GlobalMaxPool1D\n",
    "\n",
    "embedding_dim = 100\n",
    "\n",
    "model = tf.keras.models.load_model('corfo_embedding.h5')\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MERCADO_ANALISTA']=y_pred>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(y_pred):\n",
    "    if y_pred > 0.5:\n",
    "        return 'Reclamo Valores'\n",
    "    else: \n",
    "        return 'APIA -Reclamo Seguros'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4      True\n",
       "      ...  \n",
       "95     True\n",
       "96     True\n",
       "97    False\n",
       "98    False\n",
       "99    False\n",
       "Name: MERCADO_ANALISTA, Length: 100, dtype: bool"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MERCADO_ANALISTA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['MERCADO_ANALISTA'] = np.where((df['MERCADO_ANALISTA'] == True),'Reclamo Valores',df['MERCADO_ANALISTA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((df['MERCADO_ANALISTA']==False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.local/lib/python3.6/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df['MERCADO_ANALISTA'].loc[df['MERCADO_ANALISTA']==False]='APIA -Reclamo Seguros'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sergio/.local/lib/python3.6/site-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  iloc._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df['MERCADO_ANALISTA'].loc[df['MERCADO_ANALISTA']==True]='Reclamo Valores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     APIA -Reclamo Seguros\n",
       "1     APIA -Reclamo Seguros\n",
       "2     APIA -Reclamo Seguros\n",
       "3     APIA -Reclamo Seguros\n",
       "4           Reclamo Valores\n",
       "              ...          \n",
       "95          Reclamo Valores\n",
       "96          Reclamo Valores\n",
       "97    APIA -Reclamo Seguros\n",
       "98    APIA -Reclamo Seguros\n",
       "99    APIA -Reclamo Seguros\n",
       "Name: MERCADO_ANALISTA, Length: 100, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MERCADO_ANALISTA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CASO_ID', 'DESCRIPCION_CIUDADANO', 'PETICION_CIUDADANO', 'data',\n",
       "       'MERCADO_ANALISTA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['data'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('predicciones.xlsx')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
